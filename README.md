# BioRhythm X â€” Research-Grade AI Backend

> **Wearable Health + Nutrition Intelligence Platform**
> Python FastAPI Â· PostgreSQL Â· Redis Â· WebSockets Â· JWT Â· Docker Â· ML (PyTorch + scikit-learn)

---

## ğŸ—‚ï¸ Project Structure

```
D:\1.0\
â”œâ”€â”€ main.py                          # FastAPI entry point
â”œâ”€â”€ .env                             # Environment config
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config.py                    # Settings (pydantic-settings)
â”‚   â”œâ”€â”€ database.py                  # Async SQLAlchemy engine + session
â”‚   â”œâ”€â”€ logging_config.py            # Loguru structured logging
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                      # SQLAlchemy ORM models
â”‚   â”‚   â”œâ”€â”€ user.py                  # User + BaselineProfile
â”‚   â”‚   â”œâ”€â”€ vitals.py                # LiveVitals
â”‚   â”‚   â”œâ”€â”€ step_metrics.py          # StepMetrics
â”‚   â”‚   â”œâ”€â”€ calorie_metrics.py       # CalorieMetrics
â”‚   â”‚   â”œâ”€â”€ diet.py                  # DietPlan + MealPlan + MacroTargets
â”‚   â”‚   â”œâ”€â”€ anomaly.py               # AnomalyLog
â”‚   â”‚   â””â”€â”€ ml_models.py             # MLModelVersion + DatasetRecord
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/                      # FastAPI routers
â”‚   â”‚   â”œâ”€â”€ auth.py                  # Register, Login, Refresh, /me
â”‚   â”‚   â”œâ”€â”€ websocket.py             # ws://â€¦/ws/vitals/{user_id}
â”‚   â”‚   â”œâ”€â”€ vitals.py                # POST /ingest, GET /history
â”‚   â”‚   â”œâ”€â”€ steps.py                 # POST /analyze
â”‚   â”‚   â”œâ”€â”€ calories.py              # POST /estimate
â”‚   â”‚   â”œâ”€â”€ diet.py                  # POST /plan, /adapt, GET /food-db
â”‚   â”‚   â”œâ”€â”€ predictions.py           # POST /analyze
â”‚   â”‚   â”œâ”€â”€ anomaly.py               # POST /detect, GET /logs/{user_id}
â”‚   â”‚   â”œâ”€â”€ risk.py                  # POST /score
â”‚   â”‚   â””â”€â”€ datasets.py              # GET /list, /status, POST /download, /upload
â”‚   â”‚
â”‚   â”œâ”€â”€ step_engine/
â”‚   â”‚   â””â”€â”€ step_service.py          # Peak detection, gait, cadence, activity
â”‚   â”‚
â”‚   â”œâ”€â”€ calorie_engine/
â”‚   â”‚   â””â”€â”€ calorie_service.py       # BMR, TDEE, VO2, fat/carb burn, fatigue
â”‚   â”‚
â”‚   â”œâ”€â”€ diet_engine/
â”‚   â”‚   â”œâ”€â”€ macro_calculator.py      # Macros, carb cycling
â”‚   â”‚   â”œâ”€â”€ meal_planner.py          # 7-day planner + adaptive engine
â”‚   â”‚   â””â”€â”€ food_database.py         # 25+ foods with macros + micronutrients
â”‚   â”‚
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â””â”€â”€ models.py                # IsolationForest + LSTM + Autoencoder
â”‚   â”‚
â”‚   â”œâ”€â”€ anomaly_engine/
â”‚   â”‚   â””â”€â”€ detector.py              # Ensemble anomaly detection
â”‚   â”‚
â”‚   â”œâ”€â”€ dataset_loader/
â”‚   â”‚   â”œâ”€â”€ registry.py              # Dataset configs (MIT-BIH, WESAD, etc.)
â”‚   â”‚   â”œâ”€â”€ downloader.py            # Async background downloader
â”‚   â”‚   â”œâ”€â”€ parser.py                # WFDB/EDF/CSV/WESAD parsers
â”‚   â”‚   â””â”€â”€ normalizer.py            # Unified internal schema mapper
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ auth_service.py          # JWT + bcrypt
â”‚   â”‚   â””â”€â”€ prediction_service.py    # 8-dimensional biometric predictor
â”‚   â”‚
â”‚   â””â”€â”€ synthetic_generator/
â”‚       â””â”€â”€ generator.py             # Synthetic wearable data
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_models.py              # Train all ML models
â”‚   â”œâ”€â”€ simulate_wearable.py         # WebSocket simulator
â”‚   â”œâ”€â”€ test_diet_plan.py            # Diet pipeline tester
â”‚   â””â”€â”€ simulate_stress.py           # Stress scenario demo
â”‚
â”œâ”€â”€ datasets/                        # Downloaded research datasets
â”‚   â”œâ”€â”€ mit_bih/
â”‚   â”œâ”€â”€ fantasia/
â”‚   â”œâ”€â”€ bidmc/
â”‚   â”œâ”€â”€ sleep_edf/
â”‚   â”œâ”€â”€ wesad/
â”‚   â””â”€â”€ mhealth/
â”‚
â””â”€â”€ ml_models/                       # Saved trained models
    â”œâ”€â”€ isolation_forest.pkl
    â”œâ”€â”€ lstm_model.pth
    â””â”€â”€ autoencoder.pth
```

---

## âš¡ Quick Start

### 1. Prerequisites

- Python 3.11+
- Docker + Docker Compose
- (Optional) CUDA GPU for faster ML training

### 2. Clone & Configure

```bash
cd D:\1.0
# Copy the env file (already pre-filled with defaults)
copy .env .env.local
```

### 3. Start Services (PostgreSQL + Redis)

```bash
docker-compose up -d db redis
```

### 4. Install Python Dependencies

```bash
pip install -r requirements.txt
```

### 5. Start the API Server

```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Open **http://localhost:8000/docs** for interactive Swagger UI.

### 6. Full Docker Deploy (all services)

```bash
docker-compose up --build
```

---

## ğŸ§ª Testing & Scripts

### Train ML Models (Synthetic Data â€” No Dataset Required)
```bash
python scripts/train_models.py --synthetic --samples 10000
```

### Train on a Real Dataset
```bash
# First download the dataset
curl -X POST "http://localhost:8000/api/datasets/download?name=mit_bih" \
  -H "Authorization: Bearer <TOKEN>"

# Then train
python scripts/train_models.py --dataset mit_bih --model isolation_forest
```

### Test Diet Plan Generation (No Server Required)
```bash
python scripts/test_diet_plan.py
```

### Simulate Stress Scenario (No Server Required)
```bash
python scripts/simulate_stress.py
```

### Simulate Wearable (Requires Running Server + Auth Token)
```bash
# 1. Register a user
curl -X POST http://localhost:8000/api/auth/register \
  -H "Content-Type: application/json" \
  -d '{"email":"test@bio.com","username":"testuser","password":"password123"}'

# 2. Login to get token
curl -X POST http://localhost:8000/api/auth/login \
  -d "username=test@bio.com&password=password123"

# 3. Run wearable simulator
python scripts/simulate_wearable.py \
  --user-id <UUID-FROM-LOGIN> \
  --token <ACCESS-TOKEN> \
  --activity Run \
  --samples 200
```

---

## ğŸ“¡ Key API Endpoints

| Method | URL | Description |
|--------|-----|-------------|
| POST | `/api/auth/register` | Register user |
| POST | `/api/auth/login` | Login â†’ JWT tokens |
| `WS` | `/ws/vitals/{user_id}` | Real-time wearable stream |
| POST | `/api/vitals/ingest` | HTTP vitals ingestion |
| POST | `/api/steps/analyze` | Gait + step analysis |
| POST | `/api/calories/estimate` | Calorie burn estimation |
| POST | `/api/diet/plan` | Generate 7-day diet plan |
| POST | `/api/diet/adapt` | Adaptive diet (HRV/stress/sleep) |
| GET | `/api/diet/food-db` | Browse food database |
| POST | `/api/predictions/analyze` | 8-dimensional biometric predictions |
| POST | `/api/anomaly/detect` | Real-time anomaly detection |
| GET | `/api/anomaly/logs/{user_id}` | Anomaly history |
| POST | `/api/risk/score` | Composite AI risk score |
| GET | `/api/datasets/list` | List all datasets |
| GET | `/api/datasets/status` | Dataset download status |
| POST | `/api/datasets/download?name=mit_bih` | Background download |
| POST | `/api/datasets/upload?name=wesad` | Manual dataset upload |

---

## ğŸ¤– ML Models

| Model | Type | Use Case |
|-------|------|----------|
| **IsolationForest** | sklearn | Real-time anomaly scoring (per-sample) |
| **LSTM** | PyTorch | Sequence-based trend prediction |
| **Autoencoder** | PyTorch | Reconstruction-based anomaly (adaptive threshold) |

**Ensemble strategy**: `0.40Ã—IsolationForest + 0.35Ã—Autoencoder + 0.25Ã—ThresholdCheck`

---

## ğŸ“Š Supported Datasets

| Dataset | Source | Signals |
|---------|--------|---------|
| **MIT-BIH Arrhythmia** | PhysioNet | ECG |
| **Fantasia** | PhysioNet | ECG, HRV |
| **BIDMC PPG** | PhysioNet | PPG, Respiration, ECG |
| **Sleep-EDF** | PhysioNet | EEG, Sleep Stages |
| **WESAD** | Uni Siegen | ECG, EDA, Stress Labels |
| **MHEALTH** | UCI | Accelerometer, Activity Labels |

**Dataset Mode** (`DATASET_MODE` in `.env`):
- `auto` â€” automatic background download
- `manual` â€” upload via `/api/datasets/upload`

---

## ğŸ§¬ Diet Intelligence Modes

| Mode | Key Features |
|------|-------------|
| **Gym Rats** | High protein, carb cycling, creatine, post-workout recovery |
| **Healthy Human** | Balanced macros, fiber, anti-inflammatory foods |
| **Fat Loss** | Calorie deficit, high satiety, metabolic adaptation |
| **Indian** | Roti, dal, paneer, regional foods |
| **Vegan/Vegetarian** | Plant-based complete proteins, B12 flagging |
| **Low Carb** | <100g carbs, high fat, electrolyte emphasis |

**Adaptive Diet**: Automatically adjusts macros if HRV drops, stress is high, sleep is poor, fatigue is elevated, or illness risk rises.

---

## ğŸ” Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `DATABASE_URL` | PostgreSQL | Async SQLAlchemy URL |
| `REDIS_URL` | redis://localhost:6379 | Redis connection |
| `JWT_SECRET_KEY` | `change-me` | JWT signing key |
| `DATASET_MODE` | `auto` | `auto` or `manual` |
| `DATASET_BASE_DIR` | `./datasets` | Dataset storage path |
| `ML_MODELS_DIR` | `./ml_models` | Trained model storage |

---

## ğŸ—ï¸ Architecture

```
WebSocket/HTTP  â†’  FastAPI Routes
                      â†“
               Services Layer
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Step Engine           â”‚  scipy peak detection + gait
          â”‚  Calorie Engine        â”‚  MET + Karvonen + VO2
          â”‚  Diet Intelligence     â”‚  Mifflin-St Jeor + Adaptive
          â”‚  Anomaly Engine        â”‚  IF + AE + Threshold
          â”‚  Prediction Service    â”‚  8-dimensional clinical scores
          â”‚  ML Models             â”‚  IsolationForest + LSTM + AE
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
          PostgreSQL (async) + Redis pub/sub
```
